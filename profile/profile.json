{
  "education": [
    {
      "awards_achievements": [
        "Dean's List 2019 - 2020",
        "Joseph Lau Student Exchange Awards",
        "Hong Kong Hua-Yan Buddhist Association Exchange Scholarships",
        "GPA: 3.54/4.3"
      ],
      "degree": "Bachelor of Business Administration",
      "department": "Department of Management",
      "duration": "2016-2020",
      "school_name": "City University of Hong Kong"
    }
  ],
  "github_repo_root_url": "https://github.com/Jarvis-Consulting-Group/jarvis_data_eng-alextjin",
  "highlighted_projects": [
    {
      "description": "I played a significant role in an on-prem-to-cloud project that involved integrating new data sources. I actively contributed by establishing connections with these new data sources and constructing the project-specific database. This involved creating over 650 tables to facilitate efficient data storage and retrieval. Additionally, I designed and developed more than 20 ETL workflows using Informatica, ensuring smooth data transformations and transfers. To optimize operations, I leveraged Airflow and worked on three DAGs (Directed Acyclic Graphs) for workflow orchestration. Furthermore, I implemented bash scripts to automate tasks and monitor the performance of these workflows, enabling streamlined operations and efficient performance monitoring.",
      "name": "RISE"
    }
  ],
  "jarvis_projects": [
    {
      "description": "Reduced the workload of the Linux Cluster Administration (LCA) team by developing several scripts that track instance performance. I used Docker in implementation and testing to ensure consistent execution. The 'psql_docker.sh' script facilitates container creation and activation. 'host_info.sh' and 'host_usage.sh' extract platform details, with the latter scheduled using crontab for continuous data collection, minimizing manual intervention. All data is stored in a PSQL instance for future analytics. Git was utilized as the version control tool, with all project scripts accessible on GitHub for collaboration and transparency.",
      "git_url": "https://github.com/Jarvis-Consulting-Group/jarvis_data_eng-alextjin/tree/master/linux_sql",
      "name": "Cluster Monitor"
    }
  ],
  "name": "Alex Tjin",
  "others": [
    {
      "bullets": [
        "Microsoft Certified: Azure Data Fundamentals",
        "IBM Agile Explorer"
      ],
      "title": "Certificates"
    },
    {
      "bullets": [
        "Basketball player",
        "Hodophile"
      ],
      "title": "Activities/Hobbies"
    }
  ],
  "professional_experience": [
    {
      "company": "Jarvis",
      "description": "Engaged in various projects and bolstered my skills and proficiency in data engineering, encompassing the area of Linux, SQL, Python, Spark, and Hadoop. Working in an agile team. Having hands-on experience in Git \u0026 Docker.",
      "duration": "2023-present",
      "title": "Data Engineer"
    },
    {
      "company": "IBM",
      "description": "Leveraged tools like Informatica, Apache Airflow, and AWS services to architect scalable and efficient data integration workflows, encompassed ingesting data from various sources (e.g csv, json, xml), employing Python in data cleansing and transformation, automated routine tasks in Bash. Also, maintained data warehouse integrity and swiftly rectify defects. Built report in Cognos \u0026 SQL.",
      "duration": "2021-2023",
      "title": "Data Engineer"
    }
  ],
  "skills": {
    "competent": [
      "Airflow",
      "AWS",
      "Spark",
      "Data Warehousing",
      "Git",
      "Docker"
    ],
    "familiar": [
      "VBA",
      "Data Visualisation",
      "Regression Testing",
      "Hadoop",
      "GCP"
    ],
    "proficient": [
      "Javascript",
      "Typescript",
      "Node",
      "Angular",
      "REST API",
      "SQL",
      "Python",
      "Bash",
      "Redshift",
      "Oracle",
      "Informatica"
    ]
  },
  "summary": "As a dedicated Data Engineer, I bring over three years of comprehensive IT development experience to the table. My expertise primarily revolves around data ingestion and integration, where I excel in leveraging Python, SQL, and Bash to seamlessly handle data workflows. I possess extensive knowledge of diverse databases, including Redshift, Oracle, and Postgres, allowing me to efficiently manage and manipulate data at scale. Furthermore, I have honed my skills in constructing robust Data Pipelines utilizing cutting-edge ETL tools like Informatica and Airflow. These tools enable me to orchestrate and automate complex data processes, ensuring streamlined data integration and efficient information flow. Also, I have acquired valuable exposure and hands-on experience with the three major cloud service providers AWS, Azure, and GCP, which enable me to design and implement scalable and performant data solutions that leverage the power and versatility of these platforms."
}
